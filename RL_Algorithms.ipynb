{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este archivo es para implementar algunos algoritmos de aprendizaje por refuerzo y aplicarlos utilizando Open AI gym.\n",
    "\n",
    "Se van a probar los siguientes 2 entornos (environments), de acuerdo con los resultados presentados en el articulo de Diego:\n",
    "\n",
    "Pendulum-v0 y Hopper-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tareas (Puede cambiar):\n",
    "1. Terminar el curso de David Silver. (Completo: 100%)\n",
    "2. Implementar con table lookup. (En progreso: Ya medio funciona (por ahi un 80%))\n",
    "3. Implementar con DQN. (Sin comenzar)\n",
    "4. Implementar con Simglucose (Sin comenzar)\n",
    "5. Implementar con el trabajo de Diego."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import progressbar\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, tamano_minimo = 1000, tamano_maximo = 10**6, tamano_batch = 32):\n",
    "        self.tamano_buffer = 0\n",
    "        self.tamano_batch = tamano_batch\n",
    "        self.tamano_minimo = tamano_minimo\n",
    "        self.tamano_maximo = tamano_maximo\n",
    "        self.buffer = np.empty(1)\n",
    "        \n",
    "    def agregarDato(self, x, a, r, xp):\n",
    "        dato = dict({'St':x, 'At':a, 'Rt+1':r, 'St+1':xp})\n",
    "        \n",
    "        self.buffer = np.append(self.buffer, dato)\n",
    "        self.tamano_buffer += 1\n",
    "        \n",
    "        if(self.tamano_buffer > self.tamano_maximo):\n",
    "            self.buffer = np.delete(self.buffer, 0)\n",
    "            self.tamano_buffer -= 1\n",
    "            \n",
    "        if(self.tamano_buffer == 0):\n",
    "            self.buffer = np.append(self.buffer, dato)\n",
    "            self.buffer = np.delete(self.buffer, 0)\n",
    "            self.tamano_buffer =1\n",
    "    \n",
    "    def darMuestras(self):\n",
    "        indices = np.random.choice(range(self.tamano_buffer), size = self.tamano_batch, replace = False)\n",
    "        return self.buffer[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 7 3 6 5]\n",
      "[{'A': 0, 'B': 1} {'A': 0, 'B': 1} {'A': 0, 'B': 1} {'A': 0, 'B': 1}\n",
      " {'A': 0, 'B': 1}]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([dict({'A':0,\n",
    "              'B':1}) \n",
    "        for i in range(10)])\n",
    "test2 = np.empty(1)\n",
    "indices = np.random.choice(range(10), size = 5, replace = False)\n",
    "print(indices)\n",
    "print(test[indices])\n",
    "\n",
    "test3 = np.append(test2, dict({'A':1, 'B':3}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'A': 1, 'B': 3}], dtype=object)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Lookup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pendulum-v0<br /> \n",
    "Utilizando el algoritmo de Sarsa.<br />\n",
    "Está como chambón pero funciona."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def darIndice(pS):\n",
    "    return int(round(pS, 1)*10+10)\n",
    "\n",
    "def escogerAccion(pS1, pS2, pS3):\n",
    "    num = np.random.random()\n",
    "    \n",
    "    if(num <= epsilon):\n",
    "        ind = np.random.randint(0,41)\n",
    "        return ind\n",
    "    else:\n",
    "        ind = np.where(tablaQ[pS1, pS2, pS3, :] == np.amax(tablaQ[pS1, pS2, pS3, :]))\n",
    "        ind = ind[0]\n",
    "        \n",
    "        if(len(ind) > 1):\n",
    "            return np.random.choice(ind)\n",
    "        else:\n",
    "            return ind\n",
    "    \n",
    "    return accion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "envName = 'Pendulum-v0'\n",
    "\n",
    "g = 0.9\n",
    "alpha = 0.5\n",
    "epsilon = 0.1 #Entre 0 y 1\n",
    "maxIter = 1500000\n",
    "ventana = 100\n",
    "epsilonIterLimit = maxIter*0.9\n",
    "\n",
    "tablaQ = np.ones((21,21,17,41))*-16\n",
    "rewards = np.zeros(int(maxIter/10))\n",
    "\n",
    "env = gym.make(envName)\n",
    "observation = env.reset()\n",
    "\n",
    "s1 = darIndice(observation[0])\n",
    "s2 = darIndice(observation[1])\n",
    "s3 = int(round(observation[2], 0) + 8)\n",
    "a = escogerAccion(s1, s2, s3)\n",
    "\n",
    "suma = 0\n",
    "\n",
    "for i in progressbar.progressbar(range(maxIter)):\n",
    "    \n",
    "    if(i > maxIter-2000):\n",
    "        env.render()\n",
    "    \n",
    "    observation, reward, done, info = env.step([(a-20)/10.0])\n",
    "    observation = np.reshape(observation, (3,))\n",
    "    \n",
    "    s1p = darIndice(observation[0])\n",
    "    s2p = darIndice(observation[1])\n",
    "    s3p = int(round(observation[2], 0) + 8)\n",
    "    \n",
    "    ap = escogerAccion(s1p, s2p, s3p)\n",
    "    \n",
    "    r = reward #Por ahora\n",
    "    suma+=r\n",
    "    \n",
    "    if(i % ventana == 0):\n",
    "        rewards[int(i/ventana)] = suma/ventana\n",
    "        suma = 0\n",
    "    \n",
    "    tablaQ[s1, s2, s3, a] = tablaQ[s1, s2, s3, a] + alpha*(r + g*tablaQ[s1p, s2p, s3p, ap] - tablaQ[s1,s2,s3,a])\n",
    "    \n",
    "    s1 = s1p\n",
    "    s2 = s2p\n",
    "    s3 = s3p\n",
    "    a = ap\n",
    "    \n",
    "    if(i > epsilonIterLimit):\n",
    "        epsilon = 0\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in progressbar.progressbar(range(2000)):\n",
    "    env.render()\n",
    "    \n",
    "    observation, reward, done, info = env.step([(a-20)/10.0])\n",
    "    observation = np.reshape(observation, (3,))\n",
    "    \n",
    "    s1p = darIndice(observation[0])\n",
    "    s2p = darIndice(observation[1])\n",
    "    s3p = int(round(observation[2], 0) + 8)\n",
    "    \n",
    "    ap = escogerAccion(s1p, s2p, s3p)\n",
    "    \n",
    "    r = reward #Por ahora\n",
    "    suma+=r\n",
    "    \n",
    "    if(i % ventana == 0):\n",
    "        rewards[int(i/ventana)] = suma/ventana\n",
    "        suma = 0\n",
    "    \n",
    "    tablaQ[s1, s2, s3, a] = tablaQ[s1, s2, s3, a] + alpha*(r + g*tablaQ[s1p, s2p, s3p, ap] - tablaQ[s1,s2,s3,a])\n",
    "    \n",
    "    s1 = s1p\n",
    "    s2 = s2p\n",
    "    s3 = s3p\n",
    "    a = ap\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creando red neuronal\n",
    "def crearModelo(n1 = 20, n2 = 41, learning_rate = 0.01):\n",
    "    modelo = Sequential()\n",
    "    \n",
    "    modelo.add(Dense(n1, activation = 'relu', input_shape = (3,)))\n",
    "    modelo.add(Dense(n1, activation = 'relu'))\n",
    "    modelo.add(Dense(n2, activation = 'linear'))\n",
    "    \n",
    "    sgd = optimizers.sgd(lr = learning_rate)\n",
    "    \n",
    "    modelo.compile(loss = 'mean_squared_error', optimizer = sgd, metrics = ['accuracy'])\n",
    "    \n",
    "    return modelo\n",
    "\n",
    "def escogerAccion(pModelo, pX):\n",
    "    num = np.random.random()\n",
    "    \n",
    "    if(num <= epsilon):\n",
    "        ind = np.random.randint(0,41)\n",
    "        return ind\n",
    "    else:\n",
    "        ind = np.argmax(pModelo.predict(pX.T))\n",
    "        return ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% (1000 of 1000) |####################| Elapsed Time: 0:00:00 Time:  0:00:00\n",
      "N/A% (0 of 3000) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_55_input to have shape (3,) but got array with shape (32,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-172-c0060b759cf8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrEnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmaxQvalores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m     \u001b[0myEnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodelo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxEnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtamano_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1441\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1442\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1443\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/tf/lib/python3.6/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_55_input to have shape (3,) but got array with shape (32,)"
     ]
    }
   ],
   "source": [
    "envName = 'Pendulum-v0'\n",
    "\n",
    "modelo = crearModelo(learning_rate = 0.001)\n",
    "\n",
    "#Con los parametros default.\n",
    "buffer = ExperienceReplay()\n",
    "\n",
    "gamma = 0.99\n",
    "alpha = 0.35\n",
    "epsilon = 1#Entre 0 y 1\n",
    "epsilonDecay = 0.99\n",
    "\n",
    "episodes = 3000\n",
    "ventana = 100\n",
    "contadores = np.zeros((1,41))\n",
    "\n",
    "rewards = np.zeros(int(episodes/ventana))\n",
    "\n",
    "env = gym.make(envName)\n",
    "observation = env.reset()\n",
    "\n",
    "x = np.reshape(observation, (1,3))\n",
    "\n",
    "a = escogerAccion(modelo, x)\n",
    "\n",
    "suma = 0\n",
    "\n",
    "#Este es un for inicial donde se almacena la cantidad minima de datos requerida en el buffer\n",
    "#antes de comenzar con el entrenamiento.\n",
    "for i in progressbar.progressbar(range(buffer.tamano_minimo)):\n",
    "    observation, reward, done, info = env.step([(a-20.0)/10.0])\n",
    "    \n",
    "    xp = np.reshape(observation, (1,3))\n",
    "    \n",
    "    x = xp\n",
    "    \n",
    "    buffer.agregarDato(x, a, r, xp)\n",
    "    \n",
    "    #epsilon es 1 asi que siempre va a escoger al azar.\n",
    "    a = escogerAccion(modelo, x)\n",
    "    \n",
    "for i in progressbar.progressbar(range(episodes)):\n",
    "    \n",
    "    if(i > episodes-1000):\n",
    "        env.render()\n",
    "    \n",
    "    contadores[0,a] += 1\n",
    "    observation, reward, done, info = env.step([(a-20.0)/10.0])\n",
    "    \n",
    "    xp = observation\n",
    "    xp = np.reshape(xp, (1,3))\n",
    "    \n",
    "    buffer.agregarDato(x, a, reward, xp)\n",
    "    \n",
    "    muestras = buffer.darMuestras()\n",
    "    \n",
    "    #Pasar esto a un metodo solito\n",
    "    xEnt = np.empty((1,3))\n",
    "    aEnt = np.empty(1)\n",
    "    rEnt = np.empty(1)\n",
    "    xpEnt = np.empty((1,3))\n",
    "    \n",
    "    for m in muestras:\n",
    "        xEnt = np.append(xEnt, m.get('St'), axis = 0)\n",
    "        aEnt = np.append(aEnt, [m.get('At')], axis = 0)\n",
    "        rEnt = np.append(rEnt, [m.get('Rt+1')], axis = 0)\n",
    "        xpEnt = np.append(xpEnt, m.get('St+1'), axis = 0)\n",
    "    \n",
    "    xEnt = np.delete(xEnt, 0, axis = 0)\n",
    "    aEnt = np.delete(aEnt, 0, axis = 0)\n",
    "    rEnt = np.delete(rEnt, 0, axis = 0)\n",
    "    xpEnt = np.delete(xpEnt, 0, axis = 0)\n",
    "    \n",
    "    qValores = modelo.predict(xEnt)\n",
    "    \n",
    "    maxQvalores = np.amax(qValores, axis = 1)\n",
    "    \n",
    "    #Aqui hay que calcular el maximo\n",
    "    targets = np.add(rEnt, gamma*maxQvalores)\n",
    "    \n",
    "    yEnt = modelo.predict(xEnt.T)\n",
    "    \n",
    "    for i in range(buffer.tamano_batch):\n",
    "        yEnt[i,aEnt[i]] = targets[i]\n",
    "    \n",
    "    modelo.fit(xEnt.T, yEnt, verbose = 0)\n",
    "    \n",
    "    x = xp\n",
    "    a = escogerAccion(modelo, x)\n",
    "    \n",
    "    epsilon = epsilon*epsilonDecay\n",
    "    \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 3)"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xEnt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "aEnt = np.append(aEnt, [test], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aEnt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 618.,  266.,  253.,  333., 1241.,  345.,  308.,  830., 1303.,\n",
       "         797.,  452.,  332.,  983.,  149.,  362.,  178., 3307.,  268.,\n",
       "         438., 1041.,  542.,  413.,  586.,  630.,  830.,  494.,  925.,\n",
       "        1385., 1835.,  428.,  368.,  713.,  669.,  751., 1593.,  508.,\n",
       "         770., 1066.,  255., 1183.,  252.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006736262610603238"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9999**50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "env = gym.make('Pendulum-v0')\n",
    "for i_episode in range(20):\n",
    "    observation = env.reset()\n",
    "    for t in range(10):\n",
    "        env.render()\n",
    "        print(observation)\n",
    "        action = env.action_space.sample()\n",
    "        observation, reward, done, info = env.step(action)\n",
    "        if done:\n",
    "            print(\"Episode finished after {} timesteps\".format(t+1))\n",
    "            break\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space)\n",
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.observation_space.high)\n",
    "print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([10,22,50,-1,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = np.where(test == np.amax(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test3[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards[10/10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer.tamano_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
